# LexChat-Multi Turn Conversation Legal Indian Legal System Chatbot

A full-stack legal question-answering system combining MERN stack with Retrieval-Augmented Generation (RAG) using hybrid search (BM25 + semantic vectors) and LLM-as-a-Judge evaluation.

## ğŸ¯ Features

- **Hybrid Retrieval**: Combines BM25 lexical matching with semantic vector search (90% accuracy on legal queries)
- **Multi-turn Conversations**: Context-aware responses with automatic summarization
- **LLM-as-a-Judge Evaluation**: 5-dimension quality assessment (factual accuracy, legal reasoning, citation quality, clarity, completeness)
- **Token Budgeting**: Automatic context trimming to stay within API limits
- **Query Rewriting**: Rewrites ambiguous follow-up queries using conversation context
- **Debug Transparency**: Shows retrieved context and token usage for every response

## ğŸ“Š Performance

| Metric | Hybrid (BM25+Vector) | Vector-Only | Improvement |
|--------|---------------------|-------------|-------------|
| Easy Questions | 100% | 71.4% | +28.6% |
| Medium Questions | 69.2% | 76.9% | -7.7% |
| Hard Questions | 80% | 70% | +10% |
| **Overall** | **83.3%** | **72.9%** | **+10.4%** |

---

## ğŸ—ï¸ Architecture

```
legal_mern_chatbot/
â”œâ”€â”€ frontend/          # React UI
â”œâ”€â”€ backend/           # Node.js/Express API
â””â”€â”€ rag_service/       # Python RAG + FastAPI
    â”œâ”€â”€ data/          # PDF documents (Indian Constitution, UDHR)
    â”œâ”€â”€ src/           # RAG pipeline modules
    â”œâ”€â”€ vector_store/  # FAISS index + embeddings
    â””â”€â”€ main.py        # FastAPI server
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Node.js** 16+ and npm
- **Python** 3.8+ with pip
- **MongoDB** I used MongoDB Compass
- **Groq API Key** 

---

## ğŸ“¦ Installation

### 1. Clone Repository

```bash
git clone (https://github.com/keerthanag3106/LexChat_legalRAG_chatBot.git )
cd legal_mern_chatbot
```

### 2. Setup RAG Service (Python)

```bash
cd rag_service

# Create virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Activate (Mac/Linux)
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

**Create `rag_service/.env`:**
```env
MONGODB_URI=mongodb://local.../legal_mern
GROQ_API_KEY=groq_api_key
RAG_DATA_FOLDER=./data
PORT=8000
MODEL_MAX_TOKENS=6000
RESERVED_RESPONSE_TOKENS=1000
RETRIEVE_K=5
ENABLE_TURN_SUMMARIZATION=true
MONGO_DB_NAME=db_name
```

**Download Legal Documents:**

Place these PDFs in `rag_service/data/`:
1. [Indian Constitution](https://cdnbbsr.s3waas.gov.in/s380537a945c7aaa788ccfcdf1b99b5d8f/uploads/2023/05/2023050195.pdf)
2. [UDHR](https://www.ohchr.org/sites/default/files/UDHR/Documents/UDHR_Translations/eng.pdf)
download everything in rag_service/data 

**Start RAG Service:**
```bash
uvicorn main:app --host 127.0.0.1 --port 8000
```

Verify: `curl http://localhost:8000/health` â†’ `{"status":"ok","initialized":true}`

---

### 3. Setup Backend (Node.js)

```bash
cd ../backend

# Install dependencies
npm install
```

**Create `backend/.env`:**
```env
MONGODB_URI=mongodb://local...
JWT_SECRET=your_random_secret_key_here
PORT=5000
RAG_SERVICE_URL=http://localhost:5000
```

**Start Backend:**
```bash
npm run dev
```

Verify: `curl http://localhost:5000/health` â†’ `{"ok":true}`

---

### 4. Setup Frontend (React)

```bash
cd ../frontend

# Install dependencies
npm install

# Start development server
npm start
```

Frontend runs on http://localhost:3000

---

## ğŸ® Usage

### Web UI

1. **Register/Login** at http://localhost:3000
2. **Create Chat**: Click "+ New" button
3. **Ask Questions**: Type legal queries (e.g., "What is Article 21?")
4. **View Debug**: Click "ğŸ” Debug" to see retrieved context and token usage
5. **Enable Evaluation**: Check "Enable LLM-as-a-Judge" for quality scores

### API Endpoints

**RAG Service (Port 8000)**

```bash
# Health check
GET /health

# Initialize/rebuild vector store
POST /initialize
{
  "force_rebuild": true
}

# Create chat session
POST /sessions
{
  "user_id": "user123",
  "title": "Legal Query"
}

# Chat (with history)
POST /chat
{
  "session_id": "uuid",
  "query": "What is Article 21?",
  "include_history": true,
  "evaluate": false
}

# Reset session
POST /sessions/{session_id}/reset
```

**Backend (Port 5000)**

```bash
# Register
POST /api/auth/register
{
  "email": "user@example.com",
  "password": "password123"
}

# Login
POST /api/auth/login
{
  "email": "user@example.com",
  "password": "password123"
}

# List chats (requires auth token)
GET /api/chats
Headers: { "Authorization": "Bearer <token>" }

# Send message
POST /api/chats/{chatId}/messages
{
  "text": "What is Article 21?",
  "evaluate": false
}
```

---

## ğŸ§ª Running Benchmark

Evaluate hybrid vs vector-only retrieval:

```bash
cd rag_service

# Ensure rag_service is running (port 8000)

# Run benchmark
python benchmark_retrieval.py
```

**Output:**
```
Running benchmark: Human Rights Legal RAG Benchmark
Total questions: 30

================================================================================
OVERALL RESULTS
================================================================================
Hybrid Retrieval Hit@3 Accuracy: 83.3% (25/30)
Vector-Only Hit@3 Accuracy:      72.9% (22/30)
Absolute Improvement:            +10.4%

BREAKDOWN BY DIFFICULTY
EASY    : Hybrid 100.0% | Vector 71.4% | Gain: +28.6%
MEDIUM  : Hybrid 69.2% | Vector 76.9% | Gain: -7.7%
HARD    : Hybrid 80.0% | Vector 70.0% | Gain: +10.0%
```

Results saved to `benchmark_results.json`

---

## ğŸ”§ Configuration

### Adjust Hybrid Search Balance

Edit `rag_service/src/hybrid_retriever.py`:

```python
# In search() method, adjust alpha (0-1)
# alpha=0.9 â†’ 90% vector, 10% BM25
# alpha=0.5 â†’ 50% vector, 50% BM25
def search(self, query: str, k: int = 5, alpha: float = 0.6):
    # ...existing code...
```

### Toggle Turn-by-Turn Summarization

```env
# In rag_service/.env
ENABLE_TURN_SUMMARIZATION=true  # Doubles Groq API calls but saves tokens long-term
```

### Adjust Token Limits

```env
MODEL_MAX_TOKENS=6000           # Total tokens available for context
RESERVED_RESPONSE_TOKENS=1000   # Reserved for model response
RETRIEVE_K=5                    # Number of chunks to retrieve
```

---

## ğŸ“ Project Structure

```
legal_mern_chatbot/
â”œâ”€â”€ README.md
â”œâ”€â”€ README_muli
â”œâ”€â”€ .gitignore
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ server.js
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ db.js
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”œâ”€â”€ authController.js
â”‚   â”‚   â””â”€â”€ chatController.js
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â””â”€â”€ auth.js
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ Conversation.js
â”‚   â”‚   â””â”€â”€ User.js
â”‚   â””â”€â”€ routes/
â”‚       â”œâ”€â”€ auth.js
â”‚       â””â”€â”€ chats.js
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ index.js
â”‚   â”‚   â”œâ”€â”€ App.js
â”‚   â”‚   â”œâ”€â”€ i18n.js
â”‚   â”‚   â”œâ”€â”€ styles.css
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatList.js
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatWindow.js
â”‚   â”‚   â”‚   â””â”€â”€ Navbar.js
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.js
â”‚   â”‚   â”‚   â”œâ”€â”€ EvaluationDashboard.js
â”‚   â”‚   â”‚   â”œâ”€â”€ LandingPage.js
â”‚   â”‚   â”‚   â”œâ”€â”€ Login.js
â”‚   â”‚   â”‚   â””â”€â”€ Register.js
â”‚   â”‚   â”œâ”€â”€ locales/
â”‚   â”‚   â”‚   â”œâ”€â”€ as.json
â”‚   â”‚   â”‚   â”œâ”€â”€ bn.json
â”‚   â”‚   â”‚   â”œâ”€â”€ en.json
â”‚   â”‚   â”‚   â”œâ”€â”€ gu.json
â”‚   â”‚   â”‚   â”œâ”€â”€ hi.json
â”‚   â”‚   â”‚   â”œâ”€â”€ kn.json
â”‚   â”‚   â”‚   â”œâ”€â”€ ml.json
â”‚   â”‚   â”‚   â”œâ”€â”€ mr.json
â”‚   â”‚   â”‚   â”œâ”€â”€ or.json
â”‚   â”‚   â”‚   â”œâ”€â”€ pa.json
â”‚   â”‚   â”‚   â”œâ”€â”€ ta.json
â”‚   â”‚   â”‚   â””â”€â”€ te.json
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ api.js
â”œâ”€â”€ rag_service/
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ benchmark_queries.json
â”‚   â”œâ”€â”€ benchmark_results.json
â”‚   â”œâ”€â”€ benchmark_retrieval.py
â”‚   â”œâ”€â”€ plot_results.py
â”‚   â”œâ”€â”€ tune_alpha.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ data/                # PDFs (Indian Constitution, UDHR, etc.)
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ conversation_manager.py
â”‚       â”œâ”€â”€ document_processor.py
â”‚       â”œâ”€â”€ hybrid_retriever.py
â”‚       â”œâ”€â”€ legal_evaluator.py
â”‚       â”œâ”€â”€ rag_pipeline.py
â”‚       â”œâ”€â”€ translation_service.py
â”‚       â”œâ”€â”€ vector_store.py
â”‚       â””â”€â”€ __pycache__/
â””â”€â”€ vector_store/
    â””â”€â”€ faiss.index
```

---

## ğŸ—„ï¸ MongoDB Collections

**Backend Database (`legal_mern`)**
- `users`: User accounts
- `conversations`: Chat sessions with messages array

**RAG Service Database (`rag_service`)**
- `sessions`: RAG session metadata
- `messages`: User/assistant messages with debug info
- `conversation_summaries`: Auto-generated summaries
- `evaluations`: LLM-as-a-Judge scores

---

## ğŸ“š Tech Stack

- **Frontend**: React, Axios
- **Backend**: Node.js, Express, JWT, Mongoose
- **RAG Service**: Python, FastAPI, FAISS, Sentence-Transformers, Groq LLM
- **Database**: MongoDB Compass
- **Search**: Hybrid (BM25 via `rank-bm25` + Semantic via `sentence-transformers`)
- **LLM**: Llama 3.1 8B via Groq API

---



## ğŸ™ Acknowledgments

- Indian Constitution text from [India.gov.in](https://www.india.gov.in)
<!-- - UDHR from [UN.org](https://www.un.org) -->
- Groq for fast LLM inference
- MongoDB Compass for database hosting
